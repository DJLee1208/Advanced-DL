{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4753fbc4-77cc-4789-9492-920667545521",
   "metadata": {},
   "source": [
    "# Setting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3651f0-2b0a-40a0-8678-3b7f959e9c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T07:53:29.771788Z",
     "iopub.status.busy": "2023-11-25T07:53:29.771320Z",
     "iopub.status.idle": "2023-11-25T07:53:39.186691Z",
     "shell.execute_reply": "2023-11-25T07:53:39.186117Z",
     "shell.execute_reply.started": "2023-11-25T07:53:29.771746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import data_aggregation\n",
    "\n",
    "source_directory = \"./../dataset/Ningbo/\"\n",
    "goal_directory = \"data_aggr/\"\n",
    "extensions = [\".hea\", \".mat\"]\n",
    "\n",
    "data_aggregation.copy_files(source_directory, goal_directory, extensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725d4b7-94cc-41c9-b6c1-02ccd7fe4473",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252d69b-04ba-4d78-8d6e-98aa29266b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T03:40:24.574663Z",
     "iopub.status.busy": "2023-11-26T03:40:24.574093Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2leads...\n",
      "Loading data...\n",
      "training samples: 31039\n",
      "evaluation samples: 3446\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [1/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  54.26861381530762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000   PNC: 0.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [2/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.63292384147644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001   PNC: 0.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [3/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.66720747947693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002   PNC: 0.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [4/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.56796050071716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003   PNC: 0.4785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [5/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.599127531051636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004   PNC: 0.4854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [6/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.62865924835205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005   PNC: 0.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [7/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.57131314277649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006   PNC: 0.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [8/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.70664119720459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007   PNC: 0.6248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [9/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.664668798446655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008   PNC: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [10/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.7120680809021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009   PNC: 0.6530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [11/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.71026039123535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010   PNC: 0.6971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [12/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.711379289627075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011   PNC: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [13/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.695536851882935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012   PNC: 0.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [14/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.699761152267456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013   PNC: 0.7054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [15/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.68180561065674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014   PNC: 0.6967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [16/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.60864806175232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015   PNC: 0.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [17/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.598450660705566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016   PNC: 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [18/100] train 96.7%\r"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "from team_code import training_code\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n",
    "training_code('data_aggr', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8595fb8a-2281-45d2-8108-85ddf73dc493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T03:38:37.792236Z",
     "iopub.status.busy": "2023-11-26T03:38:37.791771Z",
     "iopub.status.idle": "2023-11-26T03:38:37.920312Z",
     "shell.execute_reply": "2023-11-26T03:38:37.919029Z",
     "shell.execute_reply.started": "2023-11-26T03:38:37.792185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedca4ce-ffed-4e5a-82c7-0fbb1954e6a6",
   "metadata": {},
   "source": [
    "# Tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52650213-f920-47bc-8c23-6fd748da727b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T10:26:34.921419Z",
     "iopub.status.busy": "2023-11-27T10:26:34.920960Z",
     "iopub.status.idle": "2023-11-27T10:26:35.736028Z",
     "shell.execute_reply": "2023-11-27T10:26:35.735230Z",
     "shell.execute_reply.started": "2023-11-27T10:26:34.921318Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/painstudy/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "\n",
    "# set gpu device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9324fc8-b907-4c10-b7cd-8dd25121b739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T10:26:36.203433Z",
     "iopub.status.busy": "2023-11-27T10:26:36.202933Z",
     "iopub.status.idle": "2023-11-27T10:26:38.939410Z",
     "shell.execute_reply": "2023-11-27T10:26:38.938813Z",
     "shell.execute_reply.started": "2023-11-27T10:26:36.203382Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import src.config as config\n",
    "from src.data import get_dataset_from_configs, collate_into_list, get_loss_weights_and_flags\n",
    "from src.model.model_utils import get_model, get_profile\n",
    "from team_code import load_model\n",
    "from src.model.model import ECG_model\n",
    "from tent import tent\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# configuration settings\n",
    "num_leads = 12\n",
    "data_cfg = config.DataConfig(\"config/cv-%dleads.json\" % num_leads)\n",
    "preprocess_cfg = config.PreprocessConfig(\"config/preprocess.json\")\n",
    "model_cfg = config.ModelConfig(\"config/model.json\")\n",
    "run_cfg = config.RunConfig(\"config/run.json\")\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load train set\n",
    "data_directory = 'data_aggr'\n",
    "dataset_train = get_dataset_from_configs(data_cfg, preprocess_cfg, data_directory, split_idx = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a5e8460-cd48-4bff-802e-5a974ef65ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T10:26:38.941295Z",
     "iopub.status.busy": "2023-11-27T10:26:38.941013Z",
     "iopub.status.idle": "2023-11-27T10:26:41.276222Z",
     "shell.execute_reply": "2023-11-27T10:26:41.275459Z",
     "shell.execute_reply.started": "2023-11-27T10:26:38.941269Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## initialize a model\n",
    "model, params = get_model(model_cfg, len(data_cfg.leads), len(data_cfg.scored_classes))\n",
    "get_profile(model, len(data_cfg.leads), data_cfg.chunk_length)\n",
    "\n",
    "#model = load_model(model_directory = 'model', leads = '12')[3]\n",
    "state_dict = torch.load(f'model/{num_leads}leads_model.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model = tent.configure_model(model)\n",
    "params, param_names = tent.collect_params(model)\n",
    "#optimizer = TODO_optimizer(params, lr=1e-3)\n",
    "optimizer = torch.optim.Adam([{'params': params[0], 'weight_decay': run_cfg.weight_decay},\n",
    "                              {'params': params[1], 'weight_decay': 0}])\n",
    "tented_model = tent.Tent(model, optimizer, episodic=False)\n",
    "#outputs = tented_model(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e014d8f-7807-4bba-96a3-0bfc7af52514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T11:14:10.328638Z",
     "iopub.status.busy": "2023-11-27T11:14:10.328304Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/243 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "iterator_train = torch.utils.data.DataLoader(dataset_train, run_cfg.batch_size, #collate_fn=collate_into_list,\n",
    "                                                     shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "outputs_s, outputs_b, true_labels = [], [], []\n",
    "\n",
    "for B, batch in enumerate(tqdm(iterator_train)):\n",
    "    # prediction\n",
    "    outputs = tented_model(batch)\n",
    "    \n",
    "    scalar_outputs = torch.sigmoid(outputs)\n",
    "    binary_outputs = scalar_outputs > 0.5\n",
    "    \n",
    "    # change outputs to numpy\n",
    "    scalar_outputs = scalar_outputs.detach().numpy()\n",
    "    binary_outputs = binary_outputs.detach().numpy()\n",
    "    # ground-truth labels\n",
    "    labels = batch[2].detach().numpy()\n",
    "    \n",
    "    outputs_s.append(scalar_outputs)\n",
    "    outputs_b.append(binary_outputs)\n",
    "    true_labels.append(labels)\n",
    "\n",
    "    #print(f'### Batch {B} / 243 ###')\n",
    "    #evaluate_score(scalar_outputs, binary_outputs, labels)\n",
    "    #trainer.evaluate(batch, device)\n",
    "\n",
    "#inputs, features, labels = dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22ad8909-6d76-4074-9116-1b50aff67d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T11:02:26.495937Z",
     "iopub.status.busy": "2023-11-27T11:02:26.495439Z",
     "iopub.status.idle": "2023-11-27T11:10:08.736301Z",
     "shell.execute_reply": "2023-11-27T11:10:08.735509Z",
     "shell.execute_reply.started": "2023-11-27T11:02:26.495887Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/243 [00:18<1:14:45, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 0 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.994, auprc 0.907\n",
      "- Accuracy...\n",
      "acc 0.586\n",
      "- F-measure...\n",
      "f score 0.669\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/243 [00:35<1:11:24, 17.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 1 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.874\n",
      "- Accuracy...\n",
      "acc 0.570\n",
      "- F-measure...\n",
      "f score 0.743\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/243 [00:52<1:09:50, 17.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 2 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.994, auprc 0.879\n",
      "- Accuracy...\n",
      "acc 0.523\n",
      "- F-measure...\n",
      "f score 0.695\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/243 [01:09<1:08:52, 17.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 3 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.993, auprc 0.880\n",
      "- Accuracy...\n",
      "acc 0.555\n",
      "- F-measure...\n",
      "f score 0.766\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/243 [01:26<1:08:06, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 4 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.987, auprc 0.891\n",
      "- Accuracy...\n",
      "acc 0.531\n",
      "- F-measure...\n",
      "f score 0.667\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/243 [01:44<1:07:48, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 5 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.988, auprc 0.799\n",
      "- Accuracy...\n",
      "acc 0.617\n",
      "- F-measure...\n",
      "f score 0.685\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/243 [02:01<1:07:18, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 6 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.988, auprc 0.855\n",
      "- Accuracy...\n",
      "acc 0.570\n",
      "- F-measure...\n",
      "f score 0.633\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/243 [02:18<1:07:02, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 7 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.988, auprc 0.864\n",
      "- Accuracy...\n",
      "acc 0.547\n",
      "- F-measure...\n",
      "f score 0.753\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 9/243 [02:35<1:06:40, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 8 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.990, auprc 0.818\n",
      "- Accuracy...\n",
      "acc 0.578\n",
      "- F-measure...\n",
      "f score 0.666\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10/243 [02:52<1:06:25, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 9 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.874\n",
      "- Accuracy...\n",
      "acc 0.547\n",
      "- F-measure...\n",
      "f score 0.641\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11/243 [03:09<1:06:01, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 10 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.990, auprc 0.892\n",
      "- Accuracy...\n",
      "acc 0.625\n",
      "- F-measure...\n",
      "f score 0.692\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 12/243 [03:26<1:05:51, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 11 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.993, auprc 0.862\n",
      "- Accuracy...\n",
      "acc 0.617\n",
      "- F-measure...\n",
      "f score 0.564\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 13/243 [03:43<1:05:38, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 12 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.989, auprc 0.880\n",
      "- Accuracy...\n",
      "acc 0.539\n",
      "- F-measure...\n",
      "f score 0.723\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14/243 [04:00<1:05:25, 17.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 13 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.990, auprc 0.828\n",
      "- Accuracy...\n",
      "acc 0.531\n",
      "- F-measure...\n",
      "f score 0.722\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 15/243 [04:17<1:04:55, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 14 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.986, auprc 0.813\n",
      "- Accuracy...\n",
      "acc 0.523\n",
      "- F-measure...\n",
      "f score 0.601\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16/243 [04:34<1:04:32, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 15 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.994, auprc 0.907\n",
      "- Accuracy...\n",
      "acc 0.625\n",
      "- F-measure...\n",
      "f score 0.713\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17/243 [04:51<1:04:19, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 16 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.995, auprc 0.927\n",
      "- Accuracy...\n",
      "acc 0.617\n",
      "- F-measure...\n",
      "f score 0.611\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 18/243 [05:08<1:03:57, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 17 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.994, auprc 0.890\n",
      "- Accuracy...\n",
      "acc 0.617\n",
      "- F-measure...\n",
      "f score 0.689\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19/243 [05:26<1:03:43, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 18 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.984, auprc 0.852\n",
      "- Accuracy...\n",
      "acc 0.516\n",
      "- F-measure...\n",
      "f score 0.673\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20/243 [05:43<1:03:24, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 19 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.788\n",
      "- Accuracy...\n",
      "acc 0.602\n",
      "- F-measure...\n",
      "f score 0.710\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 21/243 [06:00<1:03:06, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 20 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.859\n",
      "- Accuracy...\n",
      "acc 0.625\n",
      "- F-measure...\n",
      "f score 0.683\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22/243 [06:17<1:02:48, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 21 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.992, auprc 0.902\n",
      "- Accuracy...\n",
      "acc 0.625\n",
      "- F-measure...\n",
      "f score 0.724\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 23/243 [06:34<1:02:20, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 22 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.834\n",
      "- Accuracy...\n",
      "acc 0.492\n",
      "- F-measure...\n",
      "f score 0.761\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24/243 [06:51<1:02:07, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 23 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.988, auprc 0.849\n",
      "- Accuracy...\n",
      "acc 0.508\n",
      "- F-measure...\n",
      "f score 0.616\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25/243 [07:08<1:01:57, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 24 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.993, auprc 0.890\n",
      "- Accuracy...\n",
      "acc 0.547\n",
      "- F-measure...\n",
      "f score 0.687\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 26/243 [07:25<1:01:36, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 25 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.987, auprc 0.774\n",
      "- Accuracy...\n",
      "acc 0.539\n",
      "- F-measure...\n",
      "f score 0.659\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 26/243 [07:42<1:04:17, 17.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2557223/4233140625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtented_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscalar_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/tent/tent.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_and_adapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/tent/tent.py\u001b[0m in \u001b[0;36mforward_and_adapt\u001b[0;34m(x, model, optimizer)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m#loss = softmax_entropy(outputs).mean(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "iterator_train = torch.utils.data.DataLoader(dataset_train, run_cfg.batch_size, #collate_fn=collate_into_list,\n",
    "                                                     shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "outputs_s, outputs_b, true_labels = [], [], []\n",
    "\n",
    "for B, batch in enumerate(tqdm(iterator_train)):\n",
    "    # prediction\n",
    "    outputs = tented_model(batch)\n",
    "    \n",
    "    scalar_outputs = torch.sigmoid(outputs)\n",
    "    binary_outputs = scalar_outputs > 0.5\n",
    "    \n",
    "    # change outputs to numpy\n",
    "    scalar_outputs = scalar_outputs.detach().numpy()\n",
    "    binary_outputs = binary_outputs.detach().numpy()\n",
    "    # ground-truth labels\n",
    "    labels = batch[2].detach().numpy()\n",
    "    \n",
    "    outputs_s.append(scalar_outputs)\n",
    "    outputs_b.append(binary_outputs)\n",
    "    true_lables.append(labels)\n",
    "\n",
    "    print(f'### Batch {B} / 243 ###')\n",
    "    #evaluate_score(scalar_outputs, binary_outputs, labels)\n",
    "    #trainer.evaluate(batch, device)\n",
    "\n",
    "#inputs, features, labels = dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e94a880d-edde-4d2c-baa6-50f0ae92ba22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T11:01:46.876447Z",
     "iopub.status.busy": "2023-11-27T11:01:46.876113Z",
     "iopub.status.idle": "2023-11-27T11:01:46.903708Z",
     "shell.execute_reply": "2023-11-27T11:01:46.902885Z",
     "shell.execute_reply.started": "2023-11-27T11:01:46.876413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.evaluate import *\n",
    "\n",
    "def evaluate_score(scalar_outputs, binary_outputs, labels):\n",
    "    weights_file = 'weights.csv'\n",
    "    sinus_rhythm = set(['426783006'])\n",
    "    #classes, weights = load_weights(weights_file)\n",
    "\n",
    "    # Evaluate the model by comparing the labels and outputs.\n",
    "    print('Evaluating model...')\n",
    "\n",
    "    print('- AUROC and AUPRC...')\n",
    "    auroc, auprc, auroc_classes, auprc_classes = compute_auc(labels, scalar_outputs)\n",
    "    print(f'auroc {auroc:.3f}, auprc {auprc:.3f}')\n",
    "\n",
    "    print('- Accuracy...')\n",
    "    accuracy = compute_accuracy(labels, binary_outputs)\n",
    "    print(f'acc {accuracy:.3f}')\n",
    "\n",
    "    print('- F-measure...')\n",
    "    f_measure, f_measure_classes = compute_f_measure(labels, binary_outputs)\n",
    "    print(f'f score {f_measure:.3f}')\n",
    "\n",
    "    print('- Challenge metric...')\n",
    "    #challenge_metric = compute_challenge_metric(weights, labels, binary_outputs, classes, sinus_rhythm)\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d67b4-c71a-401c-9726-aeafc516e84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad300ad2-447c-4984-98b5-3c854d12a254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "924a9ce4-f750-47b0-b187-83bbc573fbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T10:37:19.506249Z",
     "iopub.status.busy": "2023-11-27T10:37:19.505826Z",
     "iopub.status.idle": "2023-11-27T10:37:19.534545Z",
     "shell.execute_reply": "2023-11-27T10:37:19.533905Z",
     "shell.execute_reply.started": "2023-11-27T10:37:19.506209Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# team_code.run_model\n",
    "outputs_list = []\n",
    "outputs_list.append(scalar_outputs[0])\n",
    "\n",
    "classes = data_cfg.scored_classes\n",
    "num_classes = len(classes)\n",
    "labels = np.zeros(num_classes, dtype=int)\n",
    "probabilities = np.zeros(num_classes)\n",
    "for i in range(num_classes):\n",
    "    for j in range(len(outputs_list)):\n",
    "        probabilities[i] += outputs_list[j][i]\n",
    "    probabilities[i] = probabilities[i] / len(outputs_list)\n",
    "    if probabilities[i] > 0.5: labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7eef6-1940-4a9a-aa5b-72b1819f15e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b9636-7794-40c3-a32e-822c13deb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = self.model(inputs, features)\n",
    "loss = -torch.mean(labels * F.logsigmoid(outputs) + (1 - labels) * F.logsigmoid(-outputs) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c51e44-ade6-494a-8d96-b5e2f8356a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim_scheduler(cfg, params, steps_per_epoch):\n",
    "    \"\"\" configure optim and scheduler \"\"\"\n",
    "    optim = torch.optim.Adam([{'params': params[0], 'weight_decay': cfg.weight_decay},\n",
    "                              {'params': params[1], 'weight_decay': 0}])\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=cfg.learning_rate,\n",
    "                                                    steps_per_epoch=steps_per_epoch, epochs=cfg.num_epochs)\n",
    "\n",
    "    return optim, scheduler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "painstudy_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
