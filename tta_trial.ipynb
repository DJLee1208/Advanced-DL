{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a68fa26-ac07-48f3-9b6c-12dd0a16a3da",
   "metadata": {},
   "source": [
    "# tta_evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f444c-22f8-44da-9d9e-c7a198d30ad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T07:45:56.685488Z",
     "iopub.status.busy": "2023-11-28T07:45:56.684971Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Ningbo, Target: Chapman\n",
      " ### Leads: 12\n",
      "Copying data...Done.\n",
      "Loading configurations...Done.\n",
      "Loading train set & model...Done\n",
      "1. Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 6/69 [00:28<04:31,  4.30s/it]"
     ]
    }
   ],
   "source": [
    "from tta_evaluate import evaluate_tta\n",
    "\n",
    "#target_sets = ['CPSC+Extra', 'Chapman', 'CPSC+Extra', 'G12EC', 'PTB-XL'] \n",
    "target_sets = ['Chapman']\n",
    "\n",
    "for target in target_sets:\n",
    "    evaluate_tta(source='Ningbo', target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4afa5b-80a4-48a3-8855-45a2863e1173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T07:06:28.200285Z",
     "iopub.status.busy": "2023-11-28T07:06:28.199814Z",
     "iopub.status.idle": "2023-11-28T07:18:11.414345Z",
     "shell.execute_reply": "2023-11-28T07:18:11.413040Z",
     "shell.execute_reply.started": "2023-11-28T07:06:28.200236Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: PTB-XL, Target: CPSC+Extra\n",
      " ### Leads: 12\n",
      "Copying data...Done.\n",
      "Loading configurations...Done.\n",
      "Loading train set & model...Done\n",
      "1. Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:50<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.811, auprc 0.261\n",
      "- Accuracy...\n",
      "acc 0.095\n",
      "- F-measure...\n",
      "f score 0.194\n",
      "- Challenge metric...\n",
      "challenge metric: 0.3281289526372109\n",
      "Done.\n",
      "2. Norm method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [01:51<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.815, auprc 0.262\n",
      "- Accuracy...\n",
      "acc 0.095\n",
      "- F-measure...\n",
      "f score 0.194\n",
      "- Challenge metric...\n",
      "challenge metric: 0.3268100618417334\n",
      "Done.\n",
      "3. Tent - episodic method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [07:37<00:00,  9.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.819, auprc 0.261\n",
      "- Accuracy...\n",
      "acc 0.095\n",
      "- F-measure...\n",
      "f score 0.194\n",
      "- Challenge metric...\n",
      "challenge metric: 0.3266782828124095\n",
      "Done.\n",
      "4. Tent - online method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\", line 39, in _open_file\n    return open(file_like, mode), True\nFileNotFoundError: [Errno 2] No such file or directory: 'data_aggr/A1186.mat'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/painstudy/ECG_TTA/DSAIL/src/data.py\", line 45, in __getitem__\n    x, f = preprocess_signal(load_data(self.filenames[i], preprocessed, self.preprocess_cfg.preprocess_idx, preprocessed_filename=preprocessed_path),\n  File \"/home/painstudy/ECG_TTA/DSAIL/src/data.py\", line 95, in load_data\n    data = np.asarray(loadmat(filename + \".mat\")['val'], dtype=np.float32)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\", line 224, in loadmat\n    with _open_file_context(file_name, appendmat) as f:\n  File \"/home/painstudy/anaconda3/envs/keras/lib/python3.8/contextlib.py\", line 113, in __enter__\n    return next(self.gen)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\", line 17, in _open_file_context\n    f, opened = _open_file(file_like, appendmat, mode)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\", line 45, in _open_file\n    return open(file_like, mode), True\nFileNotFoundError: [Errno 2] No such file or directory: 'data_aggr/A1186.mat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2804005/1279563569.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'CPSC+Extra'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_sets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mevaluate_tta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PTB-XL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ECG_TTA/DSAIL/tta_evaluate.py\u001b[0m in \u001b[0;36mevaluate_tta\u001b[0;34m(source, target)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4. Tent - online method...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mtent_episodic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtented_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtent_episodic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{source}-{target}/tent-online_{num_leads}_leads'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mevaluate_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtented_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/tta_evaluate.py\u001b[0m in \u001b[0;36mevaluate_test\u001b[0;34m(model, iterator_train, fpath)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0mscalars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\", line 39, in _open_file\n    return open(file_like, mode), True\nFileNotFoundError: [Errno 2] No such file or directory: 'data_aggr/A1186.mat'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/painstudy/ECG_TTA/DSAIL/src/data.py\", line 45, in __getitem__\n    x, f = preprocess_signal(load_data(self.filenames[i], preprocessed, self.preprocess_cfg.preprocess_idx, preprocessed_filename=preprocessed_path),\n  File \"/home/painstudy/ECG_TTA/DSAIL/src/data.py\", line 95, in load_data\n    data = np.asarray(loadmat(filename + \".mat\")['val'], dtype=np.float32)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\", line 224, in loadmat\n    with _open_file_context(file_name, appendmat) as f:\n  File \"/home/painstudy/anaconda3/envs/keras/lib/python3.8/contextlib.py\", line 113, in __enter__\n    return next(self.gen)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\", line 17, in _open_file_context\n    f, opened = _open_file(file_like, appendmat, mode)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/scipy/io/matlab/mio.py\", line 45, in _open_file\n    return open(file_like, mode), True\nFileNotFoundError: [Errno 2] No such file or directory: 'data_aggr/A1186.mat'\n"
     ]
    }
   ],
   "source": [
    "from tta_evaluate import evaluate_tta\n",
    "\n",
    "target_sets = ['CPSC+Extra']\n",
    "for target in target_sets:\n",
    "    evaluate_tta(source='PTB-XL', target=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753fbc4-77cc-4789-9492-920667545521",
   "metadata": {},
   "source": [
    "# Setting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3651f0-2b0a-40a0-8678-3b7f959e9c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T07:53:29.771788Z",
     "iopub.status.busy": "2023-11-25T07:53:29.771320Z",
     "iopub.status.idle": "2023-11-25T07:53:39.186691Z",
     "shell.execute_reply": "2023-11-25T07:53:39.186117Z",
     "shell.execute_reply.started": "2023-11-25T07:53:29.771746Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import data_aggregation\n",
    "import os, shutil\n",
    "\n",
    "os.system(\"rm -f data_aggr\")\n",
    "\n",
    "source_directory = \"./../dataset/Ningbo/\"\n",
    "goal_directory = \"data_aggr/\"\n",
    "extensions = [\".hea\", \".mat\"]\n",
    "\n",
    "data_aggregation.copy_files(source_directory, goal_directory, extensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725d4b7-94cc-41c9-b6c1-02ccd7fe4473",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7252d69b-04ba-4d78-8d6e-98aa29266b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T03:40:24.574663Z",
     "iopub.status.busy": "2023-11-26T03:40:24.574093Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2leads...\n",
      "Loading data...\n",
      "training samples: 31039\n",
      "evaluation samples: 3446\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [1/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  54.26861381530762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000   PNC: 0.3741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [2/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.63292384147644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001   PNC: 0.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [3/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.66720747947693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002   PNC: 0.4672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [4/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.56796050071716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003   PNC: 0.4785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [5/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.599127531051636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004   PNC: 0.4854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [6/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.62865924835205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005   PNC: 0.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [7/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.57131314277649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006   PNC: 0.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [8/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.70664119720459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007   PNC: 0.6248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [9/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.664668798446655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008   PNC: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [10/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.7120680809021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009   PNC: 0.6530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [11/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.71026039123535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010   PNC: 0.6971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [12/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.711379289627075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011   PNC: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [13/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.695536851882935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012   PNC: 0.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [14/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.699761152267456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013   PNC: 0.7054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [15/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.68180561065674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014   PNC: 0.6967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [16/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.60864806175232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015   PNC: 0.6837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [17/100] train 98.8%\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  50.598450660705566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016   PNC: 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# epoch [18/100] train 96.7%\r"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "from team_code import training_code\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n",
    "training_code('data_aggr', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8595fb8a-2281-45d2-8108-85ddf73dc493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T03:38:37.792236Z",
     "iopub.status.busy": "2023-11-26T03:38:37.791771Z",
     "iopub.status.idle": "2023-11-26T03:38:37.920312Z",
     "shell.execute_reply": "2023-11-26T03:38:37.919029Z",
     "shell.execute_reply.started": "2023-11-26T03:38:37.792185Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedca4ce-ffed-4e5a-82c7-0fbb1954e6a6",
   "metadata": {},
   "source": [
    "# Tent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52650213-f920-47bc-8c23-6fd748da727b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T02:55:18.758154Z",
     "iopub.status.busy": "2023-11-28T02:55:18.757609Z",
     "iopub.status.idle": "2023-11-28T02:55:19.529549Z",
     "shell.execute_reply": "2023-11-28T02:55:19.529009Z",
     "shell.execute_reply.started": "2023-11-28T02:55:18.758007Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/painstudy/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "\n",
    "# set gpu device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94a880d-edde-4d2c-baa6-50f0ae92ba22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T02:55:19.755181Z",
     "iopub.status.busy": "2023-11-28T02:55:19.754815Z",
     "iopub.status.idle": "2023-11-28T02:55:19.765540Z",
     "shell.execute_reply": "2023-11-28T02:55:19.764869Z",
     "shell.execute_reply.started": "2023-11-28T02:55:19.755142Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate function\n",
    "from src.evaluate import *\n",
    "\n",
    "def evaluate_score(scalar_outputs, binary_outputs, labels):\n",
    "    weights_file = 'config/weights.csv'\n",
    "    sinus_rhythm = set(['426783006'])\n",
    "    classes, weights = load_weights(weights_file)\n",
    "\n",
    "    # Evaluate the model by comparing the labels and outputs.\n",
    "    print('Evaluating model...')\n",
    "\n",
    "    print('- AUROC and AUPRC...')\n",
    "    auroc, auprc, auroc_classes, auprc_classes = compute_auc(labels, scalar_outputs)\n",
    "    print(f'auroc {auroc:.3f}, auprc {auprc:.3f}')\n",
    "\n",
    "    print('- Accuracy...')\n",
    "    accuracy = compute_accuracy(labels, binary_outputs)\n",
    "    print(f'acc {accuracy:.3f}')\n",
    "\n",
    "    print('- F-measure...')\n",
    "    f_measure, f_measure_classes = compute_f_measure(labels, binary_outputs)\n",
    "    print(f'f score {f_measure:.3f}')\n",
    "\n",
    "    print('- Challenge metric...')\n",
    "    challenge_metric = compute_challenge_metric(weights, labels, binary_outputs, classes, sinus_rhythm)\n",
    "    print(f'challenge metric: {challenge_metric}')\n",
    "    \n",
    "    with open(f\"results/source_{source}-{target}_{num_leads}_leads_{challenge_metric:.3f}.txt\", 'w') as f:\n",
    "        f.write(f'auroc {auroc:.3f}, auprc {auprc:.3f}')\n",
    "        f.write(f'acc {accuracy:.3f}')\n",
    "        f.write(f'f score {f_measure:.3f}')\n",
    "        f.write(f'challenge metric: {challenge_metric}')\n",
    "    \n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9324fc8-b907-4c10-b7cd-8dd25121b739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T02:56:18.492926Z",
     "iopub.status.busy": "2023-11-28T02:56:18.492595Z",
     "iopub.status.idle": "2023-11-28T02:56:22.847498Z",
     "shell.execute_reply": "2023-11-28T02:56:22.846858Z",
     "shell.execute_reply.started": "2023-11-28T02:56:18.492895Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, os, shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import data_aggregation\n",
    "import src.config as config\n",
    "from src.data import get_dataset_from_configs, collate_into_list, get_loss_weights_and_flags\n",
    "from src.model.model_utils import get_model, get_profile\n",
    "from team_code import load_model\n",
    "from src.model.model import ECG_model\n",
    "from tent import tent\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# source, target settings\n",
    "source = 'Ningbo'\n",
    "target = 'G12EC'\n",
    "\n",
    "# configuration settings\n",
    "num_leads = 2\n",
    "\n",
    "# set target dataset\n",
    "fdir = 'data_aggr'\n",
    "if os.path.exists(fdir):\n",
    "    shutil.rmtree(fdir)\n",
    "os.mkdir(fdir)\n",
    "\n",
    "data_aggregation.copy_files(source_dir = f\"./../dataset/{target}/\", goal_dir = f\"{fdir}/\", file_extensions = [\".hea\", \".mat\"])\n",
    "\n",
    "\n",
    "# load configurations\n",
    "data_cfg = config.DataConfig(f\"config/{target}/cv-{num_leads}leads.json\")\n",
    "preprocess_cfg = config.PreprocessConfig(\"config/preprocess.json\")\n",
    "model_cfg = config.ModelConfig(\"config/model.json\")\n",
    "run_cfg = config.RunConfig(\"config/run.json\")\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load train set\n",
    "data_directory = fdir\n",
    "dataset_train = get_dataset_from_configs(data_cfg, preprocess_cfg, data_directory, split_idx = \"train\")\n",
    "\n",
    "# Iterator\n",
    "iterator_train = torch.utils.data.DataLoader(dataset_train, run_cfg.batch_size, #collate_fn=collate_into_list,\n",
    "                                                     shuffle=True, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0bd7eec-b2ed-488e-9f6d-fabd5e090dc9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-28T01:55:13.671619Z",
     "iopub.status.busy": "2023-11-28T01:55:13.671108Z",
     "iopub.status.idle": "2023-11-28T01:55:13.691910Z",
     "shell.execute_reply": "2023-11-28T01:55:13.691068Z",
     "shell.execute_reply.started": "2023-11-28T01:55:13.671568Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'filenames' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2644245/54521694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilenames_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filenames_from_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames_all\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscored_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequivalent_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/src/data.py\u001b[0m in \u001b[0;36mget_filenames_from_split\u001b[0;34m(data_cfg, dataset_idx, split_idx, data_directory)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m#     filenames = filenames[:3]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mfilenames_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;31m# filenames_all = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;31m# if (split_idx == \"train\"):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'filenames' referenced before assignment"
     ]
    }
   ],
   "source": [
    "filenames_all = get_filenames_from_split(data_cfg, dataset_idx='all', split_idx=None, data_directory=data_directory)\n",
    "X, F, Y, filenames, headers = [], [], [], [], []\n",
    "for filename in filenames_all:\n",
    "    header = load_header(filename)\n",
    "    y = preprocess_label(get_labels(header), data_cfg.scored_classes, data_cfg.equivalent_classes)\n",
    "    if np.sum(y) == 0 and not sanity_check: continue\n",
    "\n",
    "    Y.append(torch.from_numpy(y))\n",
    "    if pre_loading:\n",
    "        preprocessed = os.path.exists(filename + \"-\" + preprocess_cfg.preprocess_idx + \".npy\")\n",
    "        x, f = preprocess_signal(load_data(filename, preprocessed, preprocess_cfg.preprocess_idx),\n",
    "                                 get_info(header, data_cfg.leads), preprocess_cfg, preprocessed)\n",
    "        X.append(torch.from_numpy(x))\n",
    "        F.append(torch.from_numpy(f))\n",
    "    else:\n",
    "        filenames.append(filename)\n",
    "        headers.append(header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a5e8460-cd48-4bff-802e-5a974ef65ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T02:56:25.771953Z",
     "iopub.status.busy": "2023-11-28T02:56:25.771462Z",
     "iopub.status.idle": "2023-11-28T02:56:25.988705Z",
     "shell.execute_reply": "2023-11-28T02:56:25.988054Z",
     "shell.execute_reply.started": "2023-11-28T02:56:25.771902Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## initialize a model\n",
    "model, params = get_model(model_cfg, len(data_cfg.leads), len(data_cfg.scored_classes))\n",
    "get_profile(model, len(data_cfg.leads), data_cfg.chunk_length)\n",
    "\n",
    "#model = load_model(model_directory = 'model', leads = '12')[3]\n",
    "state_dict = torch.load(f'model/{source}/{num_leads}leads_model.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model = tent.configure_model(model)\n",
    "params, param_names = tent.collect_params(model)\n",
    "#optimizer = TODO_optimizer(params, lr=1e-3)\n",
    "optimizer = torch.optim.Adam([{'params': params[0], 'weight_decay': run_cfg.weight_decay},\n",
    "                              {'params': params[1], 'weight_decay': 0}])\n",
    "tent_episodic = True\n",
    "tented_model = tent.Tent(model, optimizer, episodic=tent_episodic)\n",
    "#outputs = tented_model(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8feec5-5863-4736-ae1e-69a69549bf92",
   "metadata": {},
   "source": [
    "## source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50bc3d9c-bdb8-4180-a689-53682a4b22e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T02:56:39.098026Z",
     "iopub.status.busy": "2023-11-28T02:56:39.097533Z",
     "iopub.status.idle": "2023-11-28T02:56:39.112539Z",
     "shell.execute_reply": "2023-11-28T02:56:39.111883Z",
     "shell.execute_reply.started": "2023-11-28T02:56:39.097975Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7500])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[49][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8589555f-d8ed-4739-8e59-6f07a0fa93be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T02:57:11.699665Z",
     "iopub.status.busy": "2023-11-28T02:57:11.699147Z",
     "iopub.status.idle": "2023-11-28T02:57:12.550105Z",
     "shell.execute_reply": "2023-11-28T02:57:12.549224Z",
     "shell.execute_reply.started": "2023-11-28T02:57:11.699615Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/67 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 175, in default_collate\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 175, in <listcomp>\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 141, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [2, 7500] at entry 0 and [12, 7500] at entry 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2756310/4138064813.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscalars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 175, in default_collate\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 175, in <listcomp>\n    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n  File \"/home/painstudy/.local/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 141, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [2, 7500] at entry 0 and [12, 7500] at entry 4\n"
     ]
    }
   ],
   "source": [
    "scalars, binaries, true_labels = [], [], []\n",
    "for B, batch in enumerate(tqdm(iterator_train)):\n",
    "    inputs, features, labels = batch\n",
    "    \n",
    "    # prediction\n",
    "    outputs = model(inputs, features)\n",
    "    \n",
    "    scalar_outputs = torch.sigmoid(outputs)\n",
    "    binary_outputs = scalar_outputs > 0.5\n",
    "    \n",
    "    # change outputs to numpy\n",
    "    scalar_outputs = scalar_outputs.detach().numpy()\n",
    "    binary_outputs = binary_outputs.detach().numpy()\n",
    "    \n",
    "    # ground-truth labels\n",
    "    labels = labels.detach().numpy()    \n",
    "    \n",
    "    scalars.extend(scalar_outputs)\n",
    "    binaries.extend(binary_outputs)\n",
    "    true_labels.extend(labels)\n",
    "    \n",
    "# save outputs\n",
    "np.savez(f'results/source_{source}-{target}_{num_leads}_leads.npz', scalar = np.array(scalars), binary = np.array(binaries), labels = np.array(true_labels))\n",
    "\n",
    "# evaluate and save results\n",
    "evaluate_score(np.array(scalars), np.array(binaries), np.array(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9bda8604-fd8e-4107-b2c2-cc26d049ea26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T13:18:28.291172Z",
     "iopub.status.busy": "2023-11-27T13:18:28.290742Z",
     "iopub.status.idle": "2023-11-27T13:18:50.428293Z",
     "shell.execute_reply": "2023-11-27T13:18:50.427635Z",
     "shell.execute_reply.started": "2023-11-27T13:18:28.291130Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.749\n",
      "- Accuracy...\n",
      "acc 0.585\n",
      "- F-measure...\n",
      "f score 0.681\n",
      "- Challenge metric...\n",
      "challenge metric: 0.8559003888488069\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# source Ningbo -> Ningbo\n",
    "evaluate_score(np.array(scalars), np.array(binaries), np.array(true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4af375-cbe2-453a-9556-108968e9cba5",
   "metadata": {},
   "source": [
    "## norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e0b183c7-a87c-4d5b-97bd-6e5ef0ff080c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T14:01:54.213076Z",
     "iopub.status.busy": "2023-11-27T14:01:54.212592Z",
     "iopub.status.idle": "2023-11-27T14:14:59.002788Z",
     "shell.execute_reply": "2023-11-27T14:14:59.002122Z",
     "shell.execute_reply.started": "2023-11-27T14:01:54.213022Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [13:00<00:00, 16.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.804, auprc 0.246\n",
      "- Accuracy...\n",
      "acc 0.101\n",
      "- F-measure...\n",
      "f score 0.170\n",
      "- Challenge metric...\n",
      "challenge metric: 0.29332773736129886\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from tent import norm\n",
    "\n",
    "# norm model\n",
    "norm_model = norm.Norm(model)\n",
    "\n",
    "scalars, binaries, true_labels = [], [], []\n",
    "\n",
    "for B, batch in enumerate(tqdm(iterator_train)):\n",
    "    inputs, features, labels = batch\n",
    "    # prediction\n",
    "    outputs = norm_model(batch)\n",
    "    \n",
    "    scalar_outputs = torch.sigmoid(outputs)\n",
    "    binary_outputs = scalar_outputs > 0.5\n",
    "    \n",
    "    # change outputs to numpy\n",
    "    scalar_outputs = scalar_outputs.detach().numpy()\n",
    "    binary_outputs = binary_outputs.detach().numpy()\n",
    "    \n",
    "    # ground-truth labels\n",
    "    labels = batch[2].detach().numpy()\n",
    "    \n",
    "    scalars.extend(scalar_outputs)\n",
    "    binaries.extend(binary_outputs)\n",
    "    true_labels.extend(labels)\n",
    "\n",
    "# save outputs\n",
    "np.savez(f'results/norm_{source}-{target}_{num_leads}_leads.npz', scalar = np.array(scalars), binary = np.array(binaries), labels = np.array(true_labels))\n",
    "\n",
    "# evaluate and save results\n",
    "evaluate_score(np.array(scalars), np.array(binaries), np.array(true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3584d7d4-2a18-40c6-9a7f-098c2bfd9093",
   "metadata": {},
   "source": [
    "## tent - episodic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6bdd31b-f3d8-447a-9a85-9e28e795c116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T01:17:16.458198Z",
     "iopub.status.busy": "2023-11-28T01:17:16.457662Z",
     "iopub.status.idle": "2023-11-28T01:17:17.208129Z",
     "shell.execute_reply": "2023-11-28T01:17:17.207086Z",
     "shell.execute_reply.started": "2023-11-28T01:17:16.458144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/47 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [16, 3, 15], expected input[128, 12, 7514] to have 3 channels, but got 12 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2644245/2777284690.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtented_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mscalar_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/tent/tent.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, features)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_and_adapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/tent/tent.py\u001b[0m in \u001b[0;36mforward_and_adapt\u001b[0;34m(x, features, model, optimizer)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# adapt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/src/model/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, features, flags)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    301\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 303\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    304\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [16, 3, 15], expected input[128, 12, 7514] to have 3 channels, but got 12 channels instead"
     ]
    }
   ],
   "source": [
    "tent_episodic = True\n",
    "tented_model = tent.Tent(model, optimizer, episodic=tent_episodic)\n",
    "\n",
    "scalars, binaries, true_labels = [], [], []\n",
    "\n",
    "for B, batch in enumerate(tqdm(iterator_train)):\n",
    "    inputs, features, labels = batch\n",
    "    \n",
    "    # prediction\n",
    "    outputs = tented_model(inputs, features)\n",
    "    \n",
    "    scalar_outputs = torch.sigmoid(outputs)\n",
    "    binary_outputs = scalar_outputs > 0.5\n",
    "    \n",
    "    # change outputs to numpy\n",
    "    scalar_outputs = scalar_outputs.detach().numpy()\n",
    "    binary_outputs = binary_outputs.detach().numpy()\n",
    "    \n",
    "    # ground-truth labels\n",
    "    labels = labels.detach().numpy()\n",
    "    \n",
    "    scalars.extend(scalar_outputs)\n",
    "    binaries.extend(binary_outputs)\n",
    "    true_labels.extend(labels)\n",
    "\n",
    "# save outputs\n",
    "np.savez(f\"results/tent-{'episodic' if tent_episodic else 'online'}_{source}-{target}_{num_leads}_leads.npz\", scalar = np.array(scalars), binary = np.array(binaries), labels = np.array(true_labels))\n",
    "\n",
    "\n",
    "# evaluate and save results\n",
    "evaluate_score(np.array(scalars), np.array(binaries), np.array(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e014d8f-7807-4bba-96a3-0bfc7af52514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T17:38:24.241861Z",
     "iopub.status.busy": "2023-11-27T17:38:24.241355Z",
     "iopub.status.idle": "2023-11-27T17:51:41.580090Z",
     "shell.execute_reply": "2023-11-27T17:51:41.579509Z",
     "shell.execute_reply.started": "2023-11-27T17:38:24.241812Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [13:12<00:00, 16.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.805, auprc 0.234\n",
      "- Accuracy...\n",
      "acc 0.099\n",
      "- F-measure...\n",
      "f score 0.172\n",
      "- Challenge metric...\n",
      "challenge metric: 0.29053739564091824\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "tent_episodic = True\n",
    "tented_model = tent.Tent(model, optimizer, episodic=tent_episodic)\n",
    "\n",
    "scalars, binaries, true_labels = [], [], []\n",
    "\n",
    "for B, batch in enumerate(tqdm(iterator_train)):\n",
    "    inputs, features, labels = batch\n",
    "    \n",
    "    # prediction\n",
    "    outputs = tented_model(inputs, features)\n",
    "    \n",
    "    scalar_outputs = torch.sigmoid(outputs)\n",
    "    binary_outputs = scalar_outputs > 0.5\n",
    "    \n",
    "    # change outputs to numpy\n",
    "    scalar_outputs = scalar_outputs.detach().numpy()\n",
    "    binary_outputs = binary_outputs.detach().numpy()\n",
    "    \n",
    "    # ground-truth labels\n",
    "    labels = labels.detach().numpy()\n",
    "    \n",
    "    scalars.extend(scalar_outputs)\n",
    "    binaries.extend(binary_outputs)\n",
    "    true_labels.extend(labels)\n",
    "\n",
    "# save outputs\n",
    "np.savez(f\"results/tent-{'episodic' if tent_episodic else 'online'}_{source}-{target}_{num_leads}_leads.npz\", scalar = np.array(scalars), binary = np.array(binaries), labels = np.array(true_labels))\n",
    "\n",
    "\n",
    "# evaluate and save results\n",
    "evaluate_score(np.array(scalars), np.array(binaries), np.array(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f161494-7fbc-4410-a0d2-76bdc25398ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T12:42:15.698232Z",
     "iopub.status.busy": "2023-11-27T12:42:15.697834Z",
     "iopub.status.idle": "2023-11-27T12:42:37.524008Z",
     "shell.execute_reply": "2023-11-27T12:42:37.523351Z",
     "shell.execute_reply.started": "2023-11-27T12:42:15.698196Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.742\n",
      "- Accuracy...\n",
      "acc 0.584\n",
      "- F-measure...\n",
      "f score 0.675\n",
      "- Challenge metric...\n",
      "challenge metric: 0.8558541691728989\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# source Ningbo -> Ningbo\n",
    "evaluate_score(np.array(scalars), np.array(binaries), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7b8af-7911-4382-88ae-656765d7d6bf",
   "metadata": {},
   "source": [
    "### tent - online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c65a559-f388-48ee-81f9-345a28f8a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tent_episodic = False\n",
    "tented_model = tent.Tent(model, optimizer, episodic=tent_episodic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d218d-d0e1-483e-bd8a-1cdf207fc9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22ad8909-6d76-4074-9116-1b50aff67d29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T11:02:26.495937Z",
     "iopub.status.busy": "2023-11-27T11:02:26.495439Z",
     "iopub.status.idle": "2023-11-27T11:10:08.736301Z",
     "shell.execute_reply": "2023-11-27T11:10:08.735509Z",
     "shell.execute_reply.started": "2023-11-27T11:02:26.495887Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/243 [00:18<1:14:45, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 0 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.994, auprc 0.907\n",
      "- Accuracy...\n",
      "acc 0.586\n",
      "- F-measure...\n",
      "f score 0.669\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/243 [00:35<1:11:24, 17.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 1 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.874\n",
      "- Accuracy...\n",
      "acc 0.570\n",
      "- F-measure...\n",
      "f score 0.743\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/243 [00:52<1:09:50, 17.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 2 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.994, auprc 0.879\n",
      "- Accuracy...\n",
      "acc 0.523\n",
      "- F-measure...\n",
      "f score 0.695\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/243 [01:09<1:08:52, 17.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 3 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.993, auprc 0.880\n",
      "- Accuracy...\n",
      "acc 0.555\n",
      "- F-measure...\n",
      "f score 0.766\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/243 [01:26<1:08:06, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 4 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.987, auprc 0.891\n",
      "- Accuracy...\n",
      "acc 0.531\n",
      "- F-measure...\n",
      "f score 0.667\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/243 [01:44<1:07:48, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 5 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.988, auprc 0.799\n",
      "- Accuracy...\n",
      "acc 0.617\n",
      "- F-measure...\n",
      "f score 0.685\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/243 [02:01<1:07:18, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 6 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.988, auprc 0.855\n",
      "- Accuracy...\n",
      "acc 0.570\n",
      "- F-measure...\n",
      "f score 0.633\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8/243 [02:18<1:07:02, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 7 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.988, auprc 0.864\n",
      "- Accuracy...\n",
      "acc 0.547\n",
      "- F-measure...\n",
      "f score 0.753\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 9/243 [02:35<1:06:40, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 8 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.990, auprc 0.818\n",
      "- Accuracy...\n",
      "acc 0.578\n",
      "- F-measure...\n",
      "f score 0.666\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10/243 [02:52<1:06:25, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 9 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.874\n",
      "- Accuracy...\n",
      "acc 0.547\n",
      "- F-measure...\n",
      "f score 0.641\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11/243 [03:09<1:06:01, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 10 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.990, auprc 0.892\n",
      "- Accuracy...\n",
      "acc 0.625\n",
      "- F-measure...\n",
      "f score 0.692\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 12/243 [03:26<1:05:51, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 11 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.993, auprc 0.862\n",
      "- Accuracy...\n",
      "acc 0.617\n",
      "- F-measure...\n",
      "f score 0.564\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 13/243 [03:43<1:05:38, 17.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 12 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.989, auprc 0.880\n",
      "- Accuracy...\n",
      "acc 0.539\n",
      "- F-measure...\n",
      "f score 0.723\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14/243 [04:00<1:05:25, 17.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 13 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.990, auprc 0.828\n",
      "- Accuracy...\n",
      "acc 0.531\n",
      "- F-measure...\n",
      "f score 0.722\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 15/243 [04:17<1:04:55, 17.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 14 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.986, auprc 0.813\n",
      "- Accuracy...\n",
      "acc 0.523\n",
      "- F-measure...\n",
      "f score 0.601\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16/243 [04:34<1:04:32, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 15 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.994, auprc 0.907\n",
      "- Accuracy...\n",
      "acc 0.625\n",
      "- F-measure...\n",
      "f score 0.713\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17/243 [04:51<1:04:19, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 16 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.995, auprc 0.927\n",
      "- Accuracy...\n",
      "acc 0.617\n",
      "- F-measure...\n",
      "f score 0.611\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 18/243 [05:08<1:03:57, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 17 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.994, auprc 0.890\n",
      "- Accuracy...\n",
      "acc 0.617\n",
      "- F-measure...\n",
      "f score 0.689\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19/243 [05:26<1:03:43, 17.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 18 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.984, auprc 0.852\n",
      "- Accuracy...\n",
      "acc 0.516\n",
      "- F-measure...\n",
      "f score 0.673\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20/243 [05:43<1:03:24, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 19 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.788\n",
      "- Accuracy...\n",
      "acc 0.602\n",
      "- F-measure...\n",
      "f score 0.710\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 21/243 [06:00<1:03:06, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 20 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.859\n",
      "- Accuracy...\n",
      "acc 0.625\n",
      "- F-measure...\n",
      "f score 0.683\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22/243 [06:17<1:02:48, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 21 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.992, auprc 0.902\n",
      "- Accuracy...\n",
      "acc 0.625\n",
      "- F-measure...\n",
      "f score 0.724\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 23/243 [06:34<1:02:20, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 22 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.991, auprc 0.834\n",
      "- Accuracy...\n",
      "acc 0.492\n",
      "- F-measure...\n",
      "f score 0.761\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24/243 [06:51<1:02:07, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 23 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.988, auprc 0.849\n",
      "- Accuracy...\n",
      "acc 0.508\n",
      "- F-measure...\n",
      "f score 0.616\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25/243 [07:08<1:01:57, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 24 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.993, auprc 0.890\n",
      "- Accuracy...\n",
      "acc 0.547\n",
      "- F-measure...\n",
      "f score 0.687\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 26/243 [07:25<1:01:36, 17.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Batch 25 / 243 ###\n",
      "Evaluating model...\n",
      "- AUROC and AUPRC...\n",
      "auroc 0.987, auprc 0.774\n",
      "- Accuracy...\n",
      "acc 0.539\n",
      "- F-measure...\n",
      "f score 0.659\n",
      "- Challenge metric...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 26/243 [07:42<1:04:17, 17.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2557223/4233140625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtented_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscalar_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/tent/tent.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_and_adapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ECG_TTA/DSAIL/tent/tent.py\u001b[0m in \u001b[0;36mforward_and_adapt\u001b[0;34m(x, model, optimizer)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m#loss = softmax_entropy(outputs).mean(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# example\n",
    "from tqdm import tqdm\n",
    "iterator_train = torch.utils.data.DataLoader(dataset_train, run_cfg.batch_size, #collate_fn=collate_into_list,\n",
    "                                                     shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "outputs_s, outputs_b, true_labels = [], [], []\n",
    "\n",
    "for B, batch in enumerate(tqdm(iterator_train)):\n",
    "    # prediction\n",
    "    outputs = tented_model(batch)\n",
    "    \n",
    "    scalar_outputs = torch.sigmoid(outputs)\n",
    "    binary_outputs = scalar_outputs > 0.5\n",
    "    \n",
    "    # change outputs to numpy\n",
    "    scalar_outputs = scalar_outputs.detach().numpy()\n",
    "    binary_outputs = binary_outputs.detach().numpy()\n",
    "    # ground-truth labels\n",
    "    labels = batch[2].detach().numpy()\n",
    "    \n",
    "    outputs_s.append(scalar_outputs)\n",
    "    outputs_b.append(binary_outputs)\n",
    "    true_lables.append(labels)\n",
    "\n",
    "    print(f'### Batch {B} / 243 ###')\n",
    "    #evaluate_score(scalar_outputs, binary_outputs, labels)\n",
    "    #trainer.evaluate(batch, device)\n",
    "\n",
    "#inputs, features, labels = dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "924a9ce4-f750-47b0-b187-83bbc573fbac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-27T10:37:19.506249Z",
     "iopub.status.busy": "2023-11-27T10:37:19.505826Z",
     "iopub.status.idle": "2023-11-27T10:37:19.534545Z",
     "shell.execute_reply": "2023-11-27T10:37:19.533905Z",
     "shell.execute_reply.started": "2023-11-27T10:37:19.506209Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# team_code.run_model\n",
    "outputs_list = []\n",
    "outputs_list.append(scalar_outputs[0])\n",
    "\n",
    "classes = data_cfg.scored_classes\n",
    "num_classes = len(classes)\n",
    "labels = np.zeros(num_classes, dtype=int)\n",
    "probabilities = np.zeros(num_classes)\n",
    "for i in range(num_classes):\n",
    "    for j in range(len(outputs_list)):\n",
    "        probabilities[i] += outputs_list[j][i]\n",
    "    probabilities[i] = probabilities[i] / len(outputs_list)\n",
    "    if probabilities[i] > 0.5: labels[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b9636-7794-40c3-a32e-822c13deb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = self.model(inputs, features)\n",
    "loss = -torch.mean(labels * F.logsigmoid(outputs) + (1 - labels) * F.logsigmoid(-outputs) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c51e44-ade6-494a-8d96-b5e2f8356a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim_scheduler(cfg, params, steps_per_epoch):\n",
    "    \"\"\" configure optim and scheduler \"\"\"\n",
    "    optim = torch.optim.Adam([{'params': params[0], 'weight_decay': cfg.weight_decay},\n",
    "                              {'params': params[1], 'weight_decay': 0}])\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=cfg.learning_rate,\n",
    "                                                    steps_per_epoch=steps_per_epoch, epochs=cfg.num_epochs)\n",
    "\n",
    "    return optim, scheduler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "painstudy_keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
